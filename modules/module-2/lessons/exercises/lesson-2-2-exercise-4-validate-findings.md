---
layout: exercise
title: "Exerc√≠cio 2.2.4: Validar e Priorizar Findings DAST"
slug: "validate-findings-dast"
lesson_id: "lesson-2-2"
module: "module-2"
difficulty: "Avan√ßado"
permalink: /modules/testes-seguranca-pratica/lessons/exercises/lesson-2-2-exercise-4-validate-findings/
lesson_url: /modules/testes-seguranca-pratica/lessons/dast-testes-dinamicos/
---

## Objetivo

Este exerc√≠cio tem como objetivo **criar processo de triagem e valida√ß√£o de findings DAST**, diferenciar false positives de true positives, e priorizar vulnerabilidades por risco real.

Ao completar este exerc√≠cio, voc√™ ser√° capaz de:

- Validar findings DAST como True Positive ou False Positive
- Analisar contexto e impacto de vulnerabilidades
- Priorizar vulnerabilidades por risco real (n√£o apenas severidade DAST)
- Criar processo documentado de triagem
- Criar dashboard de vulnerabilidades priorizadas

---

## Descri√ß√£o

Voc√™ vai executar DAST em uma aplica√ß√£o real (ou aplica√ß√£o de exemplo), validar cada finding Critical/High, diferenciar false positives de true positives, analisar contexto e impacto, e criar processo documentado de prioriza√ß√£o.

### Contexto

Nem tudo que DAST reporta √© vulnerabilidade real. √â fundamental validar findings, entender contexto, e priorizar por risco real para focar esfor√ßo onde realmente importa.

### Tarefa Principal

1. Executar DAST em aplica√ß√£o real
2. Para cada finding Critical/High:
   - Validar se √© True Positive ou False Positive
   - Analisar contexto e impacto
   - Priorizar por risco real
   - Documentar decis√£o
3. Criar dashboard de vulnerabilidades priorizadas
4. Criar processo de triagem documentado

---

## Requisitos

### Passo 1: Executar DAST em Aplica√ß√£o Real

**1.1. Escolher Aplica√ß√£o**

- Aplica√ß√£o pr√≥pria (preferido)
- Ou aplica√ß√£o de exemplo (OWASP Juice Shop, WebGoat, etc.)

**1.2. Executar DAST**

```bash
# Executar OWASP ZAP
docker exec zap zap-full-scan.py \
  -t http://localhost:3000 \
  -J zap-results.json \
  -r zap-results.html

# Ou usar Burp Suite e exportar resultados
```

**1.3. Consolidar Resultados**

Criar arquivo `dast-findings.json` com todos os findings:

```json
{
  "scan_date": "2026-01-14",
  "tool": "owasp-zap",
  "total_findings": 32,
  "by_severity": {
    "high": 3,
    "medium": 12,
    "low": 17
  },
  "findings": [
    {
      "id": "finding-001",
      "tool": "owasp-zap",
      "alert": "SQL Injection",
      "severity": "High",
      "url": "http://app.com/api/users?id=1",
      "parameter": "id",
      "evidence": "Response contains data from multiple users",
      "cwe": "CWE-89",
      "owasp": "A03:2021 ‚Äì Injection"
    }
  ]
}
```

### Passo 2: Processo de Valida√ß√£o

**2.1. Criar Template de Valida√ß√£o**

Criar arquivo `templates/validation-template-dast.md`:

```markdown
## Finding: [ID] - [Tipo de Vulnerabilidade]

### Metadados
- **Finding ID**: finding-001
- **Severidade DAST**: High üî¥
- **CWE**: CWE-89 (SQL Injection)
- **OWASP Top 10**: A03:2021 ‚Äì Injection
- **Ferramenta**: OWASP ZAP
- **URL**: `http://app.com/api/users?id=1`
- **Par√¢metro**: `id`

### Requisi√ß√£o/Resposta
```http
GET /api/users?id=1' OR '1'='1 HTTP/1.1
Host: app.com

HTTP/1.1 200 OK
[
  {"id": 1, "name": "User 1"},
  {"id": 2, "name": "User 2"}
]
```

### Payload Usado
```
1' OR '1'='1
```

### An√°lise de Contexto
- [ ] **URL est√° em produ√ß√£o?**
  - [ ] Sim - Desde quando? ___________
  - [ ] N√£o - Em staging/QA
  
- [ ] **Endpoint requer autentica√ß√£o?**
  - [ ] Sim - Tipo? ___________
  - [ ] N√£o
  
- [ ] **Dados sens√≠veis afetados?**
  - [ ] Sim - Quais? ___________
  - [ ] N√£o
  
- [ ] **Endpoint √© p√∫blico?**
  - [ ] Sim
  - [ ] N√£o - Requer autentica√ß√£o/autoriza√ß√£o
  
- [ ] **Vulnerabilidade √© reproduz√≠vel?**
  - [ ] Sim - Testado manualmente
  - [ ] N√£o - N√£o consegui reproduzir

### An√°lise de Risco

**Exploitability (F√°cil explorar?)**: ALTA / M√âDIA / BAIXA

**Justificativa**: 
[Por que √© f√°cil ou dif√≠cil explorar?]

**Impacto (Dados sens√≠veis afetados?)**: CR√çTICO / ALTO / M√âDIO / BAIXO

**Justificativa**:
[Qual o impacto se explorado?]

**Contexto do Neg√≥cio**:
- Aplica√ß√£o em produ√ß√£o: Sim / N√£o
- Volume de usu√°rios afetados: ___________
- √Årea cr√≠tica do sistema: Sim / N√£o
- Compliance afetado: Sim / N√£o - Qual? ___________

### Decis√£o

- [ ] **True Positive - Vulnerabilidade Real**
  - [ ] Corrigir imediatamente (P1)
  - [ ] Corrigir neste Sprint (P2)
  - [ ] Corrigir no pr√≥ximo Sprint (P3)
  - [ ] Backlog (P4)
  
- [ ] **False Positive - N√£o √© vulnerabilidade**
  - Raz√£o: ___________
  - [ ] Marcar como resolvido
  - [ ] Adicionar exce√ß√£o na ferramenta DAST
  
- [ ] **Risco Aceito - N√£o ser√° corrigido**
  - Justificativa: ___________
  - Mitiga√ß√µes implementadas: ___________
  - Aprova√ß√£o: ___________

### A√ß√£o Corretiva (se True Positive)

**Corre√ß√£o Implementada**:
[Como foi corrigido?]

**Valida√ß√£o**:
- [ ] DAST re-executado - Finding removido ‚úÖ
- [ ] Testes de seguran√ßa adicionados ‚úÖ
- [ ] Code review aprovado ‚úÖ
- [ ] Deploy em produ√ß√£o ‚úÖ

### Tracking
- **Issue**: SEC-XXX
- **Respons√°vel**: ___________
- **Prazo**: ___________
- **Status**: Aberto / Em andamento / Resolvido
```

**2.2. Validar Cada Finding**

Para cada finding Critical/High:

1. Reproduzir manualmente o ataque
2. Analisar resposta da aplica√ß√£o
3. Preencher template de valida√ß√£o
4. Decidir: True Positive, False Positive, ou Risco Aceito
5. Priorizar se True Positive

### Passo 3: Exemplos de Valida√ß√£o

**3.1. Exemplo 1: True Positive - SQL Injection**

```http
GET /api/users?id=1' OR '1'='1 HTTP/1.1

Response: 200 OK
[
  {"id": 1, "name": "User 1"},
  {"id": 2, "name": "User 2"},
  {"id": 3, "name": "User 3"}
]
```

**An√°lise**:
- Vulnerabilidade reproduz√≠vel? ‚úÖ Sim
- Em produ√ß√£o? ‚úÖ Sim
- Requer autentica√ß√£o? ‚ùå N√£o (endpoint p√∫blico)
- Dados sens√≠veis? ‚úÖ Sim (dados de usu√°rios)

**Decis√£o**: ‚úÖ **True Positive - P1 (Corrigir IMEDIATAMENTE)**

**Raz√£o**: SQL Injection em produ√ß√£o, endpoint p√∫blico, dados sens√≠veis afetados.

**3.2. Exemplo 2: False Positive - Missing Security Headers**

```http
GET / HTTP/1.1

Response: 200 OK
(Headers n√£o incluem X-Frame-Options)
```

**An√°lise**:
- Headers realmente ausentes? ‚úÖ Sim
- Mas aplica√ß√£o usa CSP (Content Security Policy) que √© mais moderno
- X-Frame-Options √© redundante quando CSP est√° presente

**Decis√£o**: ‚úÖ **False Positive - Marcar como resolvido**

**Raz√£o**: CSP j√° implementado, X-Frame-Options √© redundante.

### Passo 4: Prioriza√ß√£o por Risco Real

**4.1. Criar Matriz de Prioriza√ß√£o**

| Severidade DAST | Exploitability | Impacto | App em Prod | Prioridade Final | Prazo |
|----------------|----------------|---------|-------------|------------------|-------|
| High | Alta | Dados sens√≠veis | Sim | P1 - IMEDIATO | 24h |
| High | Alta | Dados sens√≠veis | N√£o | P2 - Este Sprint | 1 semana |
| Medium | Alta | Dados sens√≠veis | Sim | P2 - Este Sprint | 1 semana |
| Medium | M√©dia | Dados sens√≠veis | N√£o | P3 - Pr√≥ximo Sprint | 2 semanas |
| Low | Alta | Dados sens√≠veis | Sim | P3 - Pr√≥ximo Sprint | 2 semanas |
| Low | Baixa | Dados n√£o sens√≠veis | N√£o | P4 - Backlog | Quando poss√≠vel |

**4.2. Priorizar Findings**

Para cada finding validado como True Positive:

1. Classificar por severidade DAST
2. Avaliar exploitability (f√°cil explorar?)
3. Avaliar impacto (dados sens√≠veis?)
4. Considerar contexto (produ√ß√£o, volume de usu√°rios)
5. Atribuir prioridade final (P1, P2, P3, P4)

### Passo 5: Criar Dashboard de Vulnerabilidades

**5.1. Criar Dashboard Simplificado**

Criar arquivo `dashboard/vulnerabilities-dast.md`:

```markdown
# Dashboard de Vulnerabilidades DAST

**√öltima atualiza√ß√£o**: 2026-01-14  
**Total de Findings**: 32  
**True Positives**: 18  
**False Positives**: 14

## Prioridades

### P1 - IMEDIATO (Corrigir em 24h)
| ID | Tipo | URL | Par√¢metro | Respons√°vel | Prazo | Status |
|----|------|-----|-----------|-------------|-------|--------|
| F-001 | SQL Injection | /api/users | id | Jo√£o Silva | 2026-01-16 | Em andamento |

### P2 - Este Sprint (Corrigir em 1 semana)
[...]

## Estat√≠sticas

- **Por Severidade DAST**:
  - High: 3 findings (2 TP, 1 FP)
  - Medium: 12 findings (8 TP, 4 FP)
  - Low: 17 findings (8 TP, 9 FP)

- **Por Status**:
  - Aberto: 10
  - Em andamento: 3
  - Resolvido: 5
```

### Passo 6: Criar Processo de Triagem Documentado

**6.1. Documentar Processo**

Criar arquivo `docs/dast-triagem-processo.md`:

```markdown
# Processo de Triagem de Findings DAST

## Objetivo

Validar findings DAST, diferenciar True Positives de False Positives, e priorizar vulnerabilidades por risco real.

## Respons√°veis

- **QA de Seguran√ßa**: Valida√ß√£o inicial e triagem
- **Desenvolvedor**: An√°lise t√©cnica e corre√ß√£o
- **Tech Lead**: Aprova√ß√£o de riscos aceitos

## Processo

### 1. Execu√ß√£o de DAST
- DAST executado automaticamente em cada deploy
- DAST executado semanalmente (scheduled)
- Resultados exportados para `dast-findings.json`

### 2. Triagem Inicial
- QA de Seguran√ßa revisa findings High/Critical
- Para cada finding:
  - Reproduzir manualmente
  - Analisar resposta
  - Preencher template de valida√ß√£o

### 3. Valida√ß√£o
- True Positive ‚Üí Continuar para prioriza√ß√£o
- False Positive ‚Üí Marcar como resolvido, adicionar exce√ß√£o
- D√∫vida ‚Üí Discutir com desenvolvedor

### 4. Prioriza√ß√£o
- Usar matriz de prioriza√ß√£o
- Considerar: Severidade, Exploitability, Impacto, Contexto
- Atribuir prioridade (P1, P2, P3, P4)

### 5. Tracking
- Criar issue para cada True Positive P1/P2/P3
- Atribuir respons√°vel
- Definir prazo
- Acompanhar at√© resolu√ß√£o

## Crit√©rios de Prioriza√ß√£o

### P1 - IMEDIATO (24h)
- High + Em produ√ß√£o + Dados sens√≠veis
- High + Alta exploitability + Impacto cr√≠tico

### P2 - Este Sprint (1 semana)
- High em staging
- Medium + Em produ√ß√£o + Dados sens√≠veis

### P3 - Pr√≥ximo Sprint (2 semanas)
- Medium em staging
- Low + Em produ√ß√£o + Dados sens√≠veis

### P4 - Backlog
- Low em staging
- Vulnerabilidades com baixo risco real
```

---

## Dicas

1. **N√£o confie apenas na severidade DAST**: Avalie risco real considerando contexto
2. **False positives s√£o OK**: DAST sempre gera false positives, √© normal
3. **Documente decis√µes**: Justificativas ajudam em auditorias
4. **Priorize por impacto real**: Nem toda High √© P1 se risco real √© baixo
5. **Reavalie periodicamente**: Prioridades podem mudar com contexto
6. **Comunique com time**: Compartilhe decis√µes e prioridades

---

## Valida√ß√£o

Verifique se voc√™ completou o exerc√≠cio corretamente:

- [ ] DAST executado em aplica√ß√£o real
- [ ] Findings High/Critical validados (True Positive vs False Positive)
- [ ] Template de valida√ß√£o preenchido para cada finding
- [ ] Prioriza√ß√£o por risco real realizada (P1/P2/P3/P4)
- [ ] Dashboard de vulnerabilidades criado
- [ ] Processo de triagem documentado
- [ ] Issues criadas para True Positives P1/P2/P3

---

## Pr√≥ximos Passos

Ap√≥s completar este exerc√≠cio, voc√™ estar√° preparado para:

- Exerc√≠cio 2.2.5: Comparar Ferramentas DAST
- Implementar processo de triagem em projeto real
- Criar dashboard automatizado
- Integrar com ferramentas de tracking (Jira, GitHub Issues)

---

## üíº Contexto CWI (Exemplo Hipot√©tico)

**Cen√°rio**: Projeto financeiro hipot√©tico (Open Banking)

- **Crit√©rios rigorosos**: High sempre P1, bloqueia deploy
- **Valida√ß√£o obrigat√≥ria**: Todos os High/Critical devem ser validados antes de merge
- **Compliance**: Findings devem ser corrigidos para atender PCI-DSS
- **Dashboard semanal**: Review todas as segundas-feiras

Aplique o processo de triagem com esses crit√©rios mais rigorosos.

---

## üì§ Enviar Resposta

Complete o exerc√≠cio e envie:

1. Template de valida√ß√£o preenchido (exemplo de 3-5 findings)
2. Dashboard de vulnerabilidades priorizadas
3. Processo de triagem documentado
4. Estat√≠sticas de valida√ß√£o (quantos TP vs FP)
5. Li√ß√µes aprendidas

{% include exercise-submission-form.html %}

---

**Dura√ß√£o Estimada**: 90-120 minutos  
**N√≠vel**: Avan√ßado  
**Pr√©-requisitos**: Aula 2.2 (DAST), Exerc√≠cio 2.2.1 (OWASP ZAP) ou conhecimento de ferramentas DAST
